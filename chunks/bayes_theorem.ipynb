{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayes Theorem\n",
    "\n",
    "Goals:\n",
    "* Grasp how the mathematics of probability can be used to do statistical inference.\n",
    "* Start working through real inference problems, with pencil, paper, and PGMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "execfile('../graphics/bayes.py') # see code here for later demos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* Gelman ch. 1\n",
    "* Ivezic 5.1-5.3\n",
    "* MacKay 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampling distributions and likelihoods\n",
    "You've just been introduced to PGMs - these are a visual representation of how data are generated.\n",
    "* By filling in the blanks, we can write down a **likelihood function** (a function of model parameters), which says how probable a given data set is.\n",
    "* Properly normalized, the same expression encodes the distribution from which data are generated for fixed parameters, called the **sampling distribution**, $P($data|params$)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampling distributions and likelihoods\n",
    "*Insert example PGM from the previous lesson to illustrate*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other ingredients for principled inference\n",
    "\n",
    "$P($data|params$)$ clearly has a role to play in inferring which parameter values are consistent with the data. What else do we need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other ingredients for principled inference\n",
    "\n",
    "$P($data|params$)$ clearly has a role to play in inferring which parameter values are consistent with the data. What else do we need?\n",
    "\n",
    "* $P($params$)$, the **prior distribution**\n",
    "* $P($params|data$)$, the **posterior distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The prior distribution\n",
    "\n",
    "$P($params$)$\n",
    "* The *marginal* probability of a set of parameter values (integrated over possible data sets).\n",
    "* Consequently, *independent of the measured data*.\n",
    "* Interpretation: what we know about the model parameters *before* incorporating new knowledge in the form of the measured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The posterior distribution\n",
    "\n",
    "$P($params|data$)$\n",
    "* The probability of a model *given* the measured data.\n",
    "* Interpretation: what we know about the model parameters *after* incorporating new knowledge in the form of the measured data. In other words, the product of statistical inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Theorem\n",
    "The ingredients above are all related through the definition of conditional probability\n",
    "\n",
    "$P(\\mathrm{params}|\\mathrm{data}) = \\frac{P(\\mathrm{data}|\\mathrm{params})~P(\\mathrm{params})}{P(\\mathrm{data})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Theorem\n",
    "\n",
    " $P(\\mathrm{params}|\\mathrm{data}) = \\frac{P(\\mathrm{data}|\\mathrm{params})~P(\\mathrm{params})}{P(\\mathrm{data})}$\n",
    "\n",
    "* $P(\\mathrm{params})$: prior - what we know before doing the experiment\n",
    "* $P(\\mathrm{data}|\\mathrm{params})$: sampling distribution - probability of obtaining our data set\n",
    "* $P(\\mathrm{params}|\\mathrm{data})$: posterior - what we know after doing the experiment (\"the answer\")\n",
    "* $P(\\mathrm{data})$???: **evidence** - marginal probability of obtaining our data for any parameter values (more on this later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: measuring the flux of a source\n",
    "\n",
    "Say we want to measure the flux of a galaxy. In a given integration time, $T$, the number of counts, $N$, that we collect in our fancy CCD will be Poisson distributed\n",
    "\n",
    "$N|\\mu \\sim \\mathrm{Poisson}(\\mu)$\n",
    "\n",
    "where $\\mu=FAT$ is the average number of counts we would expect in time $T$, the product of the integration time, the source flux ($F$, counts per unit time and area), and the collecting area of our telescope ($A$).\n",
    "\n",
    "Presumably we know $A$ and $T$ well, so for convenience we can make $\\mu$ rather than $F$ the free parameter of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "$N|\\mu \\sim \\mathrm{Poisson}(\\mu)$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_poissoneg_likelihood.png\" width=400></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "*Insert PGM here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "We'll talk more about how to choose a prior in a few minutes. For now, we'll make a common choice, the uniform distribution (for $\\mu\\geq0$ in this case).\n",
    "* This is an **improper** distribution, i.e. one that can't technically be normalized. This doesn't necessarily matter, as long as the posterior distribution turns out to be proper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "$\\mu \\sim \\mathrm{Uniform}(0,\\infty)$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"../graphics/bayes_poissoneg_prior.png\" width=400></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "What about the evidence, $P(N)$?\n",
    "* This is constant with respect to model parameters by definition, so we don't actually need to calculate it (although we could, by marginalizing the sampling distribution over $\\mu$).\n",
    "* That's because we know the posterior will be a probability distribution - as long as it's proper, the normalizing constant must be whatever makes it integrate to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "Now we have everything we need to calculate $P(\\mu|N)\\propto P(N|\\mu)P(\\mu)$.\n",
    "* In a sense we're done, and could simply evaluate this for all possible $\\mu$s, but it would be nice to have a simpler form for the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: [conjugate distributions](https://en.wikipedia.org/wiki/Conjugate_prior)\n",
    "\n",
    "**Conjugate distributions** are like eigenfunctions of Bayes Theorem. These are special cases for which the form of the posterior is the same as the prior, for a specific sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "The Poisson distribution is conjugate to the Gamma distribution\n",
    "\n",
    "$P(x) = \\frac{1}{\\Gamma(\\alpha)}\\beta^\\alpha x^{\\alpha-1} e^{-\\beta x}$ for $x\\geq0$\n",
    "\n",
    "Our Uniform prior is a limiting case of Gamma (with $\\beta\\rightarrow0$), so we can take advantage of this.\n",
    "\n",
    "If we take the prior $\\mu \\sim \\mathrm{Gamma}(\\alpha_0,\\beta_0)$, the posterior will be $\\mu|N \\sim \\mathrm{Gamma}(\\alpha_0+N,\\beta_0+1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "*Insert PGM here (with alpha and beta this time)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: measuring the flux of a source\n",
    "\n",
    "Here we can demo how the posterior distribution depends on these prior **hyperparameters**, as well as the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0,7.0)\n",
    "bayesDemo(alpha0=1.0, beta0=0.001, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
