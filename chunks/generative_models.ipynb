{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Models\n",
    "\n",
    "Goals:\n",
    "* Introduce probabilistic graphical models in the context of generating mock data\n",
    "* Explore some simple practical aspects of simulating data\n",
    "* Walk through a simple mock data generation example and its PGM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* Ivezic \n",
    "* Bishop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Understanding by Modeling\n",
    "\n",
    "<table><tr width=90%>\n",
    "<td><img src=\"../graphics/tour_cluster_image.png\" height=300></td>\n",
    "<td><img src=\"../graphics/tour_cluster_image_zoom.png\" height=300></td>\n",
    "</tr></table>\n",
    "\n",
    "Understanding the features in these images means _making a model that can \"predict\" them_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When do we want to generate data?\n",
    "\n",
    "* Inference: we generate noise-free data to compare with our noisy data\n",
    "\n",
    "* Checking: to investigate whether our model is a good one or not\n",
    "\n",
    "* Testing: does our analysis recover the input model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Sampling Distribution\n",
    "\n",
    "* The noisy, mock data are drawn from a PDF known as the \"sampling distribution\"\n",
    "\n",
    "* In the case of an X-ray image pixel, containing mock counts $N_k$, this PDF is $P(N_k|\\mu_k,H)$\n",
    "\n",
    "* $\\mu_k$ is a parameter, the expected number of counts in the $k^{th}$ pixel\n",
    "\n",
    "* $H$ is the list of assumptions that defines our model\n",
    "\n",
    "> The sampling distribution is sometimes called the error distribution, and when written as a function of parameters, not data, it's called the \"likelihood\" of the parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional probability\n",
    "\n",
    "* $P((N_k|\\mu_k,H)$ is pronounced \"the probabilty for $N_k$ given $\\mu_k$ and $H$\"\n",
    "\n",
    "* This means that if you know what the value of $\\mu_k$ is, you can _draw_ a sample value of $N_k$ from $P$ - since  $H$ tells you what the functional form of $P$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sampling in practice\n",
    "\n",
    "* In general, sampling from a PDF is difficult\n",
    "\n",
    "* For certain standard distributions, however, there are fast algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 7, 0, 3, 2, 3, 3, 1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "P = scipy.stats.poisson(mu=3)\n",
    "P.rvs(size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sampling in practice\n",
    "\n",
    "* [numpy.random]() and [scipy.stats]() are two useful libraries for drawing samples from PDFs\n",
    "\n",
    "* You may have encountered some of these routines as \"random number generators\"\n",
    "\n",
    "* Sampling from a PDF means generating random numbers from that distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing the input model parameters\n",
    "\n",
    "* When testing, we often want to assert a set of input model parameters $\\theta$, and then see what they produce\n",
    "\n",
    "* Testing at large scale might involve generating many datasets, with different inputs. In this case we might want to sample from a *plausible distribution of input parameters*\n",
    "\n",
    "* In practice: choose a particular standard probability distribution for $\\theta$ and sample from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deterministic relationships\n",
    "\n",
    "* Often, our model provides a deterministic relationship between parameters: if you know $\\theta$, then you know $\\mu$\n",
    "\n",
    "* In our X-ray image case, $\\theta$ could be the set of parameters that describe the gas temperature and density profiles of a spehrically symmetric cluster of galaxies with known centroid position\n",
    "\n",
    "* $\\mu(\\theta)$ would then be some complicated function that took the cluster parameters $\\theta$ as input, and predicted the expected counts at any pixel position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilistic Graphical Models\n",
    "\n",
    "* This procedure for simulating a mock X-ray image dataset can be usefully illustrated with a _directed acyclic graph_ called a \"Probabilistic Graphical Model\"\n",
    "\n",
    "* In the present context these provide something like a \"flow diagram\" showing how we might draw a sample mock dataset from our model\n",
    "\n",
    "* Let's look at the PGM for a simple X-ray image simulation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One pixel, fixed inputs\n",
    "\n",
    "<img src=\"../graphics/pgms_one_pixel_input_fixed.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PGM pieces\n",
    "\n",
    "* Each _node_ in the graph represents a PDF, for the variable labeled inside it\n",
    "\n",
    "* Each _edge_ in the graph represents a conditional dependence\n",
    "\n",
    "* Deterministic relationships are indicated by \"fixed\" variables represented by solid points\n",
    "\n",
    "> The fixed nodes are _also_ PDFs: fixing a parameter is the same as sampling it from a delta function PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## One pixel, sampled inputs\n",
    "\n",
    "<img src=\"../graphics/pgms_one_pixel_input_sampled.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PGM interpretation\n",
    "\n",
    "* Following the arrows, the network of conditional dependences shows you how to go about simulating mock data ($N_k$)\n",
    "\n",
    "> For example: \n",
    "1. Draw a sample $\\theta$ vector;\n",
    "2. Compute $\\mu_k$ from it;\n",
    "3. Draw an $N_k$ given that $\\mu_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PGM interpretation\n",
    "\n",
    "* The graph is also an illustration of a particular factorisation of a joint probability distribution: the PDF for every variable in the model \n",
    "\n",
    "* For example: \n",
    "\n",
    "$P(N_k|\\mu_k,H)\\;P(\\mu_k|\\theta_k,H)\\;P(\\theta_k|H) =  P(N_k,\\mu_k,\\theta_k|H)$\n",
    "\n",
    "> Note that the dependence of $N_k$ on $\\theta$ has been dropped here: $N_k$ is only dependent on $\\theta$ through $\\mu_k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulating the whole image\n",
    "\n",
    "* Our model for the cluster allows us to predict all of the image pixel values, separately: each of the $\\mu_k$ depends on $\\theta$ alone\n",
    "\n",
    "* Our simple Poisson model reflects an assumption about our detector, which is that the observed counts in the $k^{th}$ pixel are independent of the observed counts in all the other pixels. $N_k$ only depends on its pixel's expected counts $\\mu_k$\n",
    "\n",
    "* In this case, the sampling distribution for all the observed pixel values $\\boldsymbol{N}$ factorizes and simplifies to\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;P(\\boldsymbol{N}|\\boldsymbol{\\mu},H) = \\prod_k P(N_k|\\mu_k,H)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## All pixels, fixed inputs\n",
    "\n",
    "<img src=\"../graphics/pgms_all_pixels_input_fixed.png\">\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;P(\\boldsymbol{N},\\boldsymbol{\\mu},\\theta|H) = \\left[ \\prod_k P(N_k|\\mu_k,H)  P(\\mu_k|\\theta,H) \\right] P(\\theta|H)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PGM pieces\n",
    "\n",
    "* Each _node_ in the graph represents a PDF, for the variable labeled inside it\n",
    "\n",
    "* Each _edge_ in the graph represents a conditional dependence\n",
    "\n",
    "* Deterministic relationships are indicated by \"fixed\" variables represented by solid points\n",
    "\n",
    "* Plates contain conditionally independent variables\n",
    "\n",
    "> Think of plates as illustrating a stack of layers, seen from above, that are only connected by their edges to variables outside the plate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take-home messages\n",
    "\n",
    "* Generating data is the key function of a statistical model\n",
    "\n",
    "* Noise-free mock datasets are central to inference; noisy mock datasets are vital for testing and model checking\n",
    "\n",
    "* Generating a mock dataset means drawing a sample from the joint probabilty distribution for all variables in the model\n",
    "\n",
    "* The \"sampling distribution\" "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
