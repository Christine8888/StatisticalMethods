{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Straight Line with `SciKit-Learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight line fitting is a [linear regression](http://scikit-learn.org/stable/modules/linear_model.html) problem - and an example of predictive learning. \n",
    "\n",
    "A predictive model will have been \"fitted\" to the data when an assumed loss function has been minimized. A popular choice of minimized loss function is the following, corresponding to the method of \"ordinary least squares\":\n",
    "\n",
    "$$ \\text{min}_{w, b} \\sum_i || w^\\mathsf{T}x_i + b  - y_i||^2 $$\n",
    "\n",
    "Let's fit some test data with a straight line using the `SciKit-Learn` library, and see how accurately we can make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Load the boston dataset, and focus on just one attribute: LSTAT (attribute 13)\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "X = np.atleast_2d(boston.data[:,12]).T\n",
    "y = np.atleast_2d(boston.target).T\n",
    "\n",
    "# Make a training/test split:\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "labels = ['LSTAT','MEDV']\n",
    "\n",
    "print X_train.shape, X_test.shape\n",
    "print y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test,  color='black')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create linear regression object:\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# The coefficients:\n",
    "print(\"Coefficients:\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The mean square prediction error:\n",
    "print(\"Training data: MSE = %.2f\"\n",
    "      % np.mean((model.predict(X_train) - y_train) ** 2))\n",
    "print(\"Test data: MSE = %.2f\"\n",
    "      % np.mean((model.predict(X_test) - y_test) ** 2))\n",
    "print \"\"\n",
    "# Explained variance score: 1 is perfect prediction:\n",
    "print('Training data: Variance score = %.2f' % model.score(X_train, y_train))\n",
    "print('Test data: Variance score = %.2f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The \"score\" $R^2$ is defined as $(1 - u/v)$, where $u$ is the *regression sum of squares* $\\sum (y_{\\rm true} - y_{\\rm pred})^2$ and $v$ is the residual sum of squares $\\sum (y_{\\rm true} - \\overline{y_{\\rm true}})^2)$. The best possible score is 1.0, lower values are worse.\n",
    "\n",
    "\n",
    "* We expect the training score to be higher than the test score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot outputs:\n",
    "plt.scatter(X_test, y_test,  color='black')\n",
    "plt.plot(X_test, model.predict(X_test), color='blue', linewidth=3)\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "\n",
    "How is this procedure different from previous occasions we have fitted a straight line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Model Prediction Accuracy\n",
    "\n",
    "* In machine learning our goal is to make the most accurate predictions we can. Above, we made one training/test split, and computed the prediction error. The model that minimizes the *generalized prediction error* can be found (approximately) with *cross validation*.\n",
    "\n",
    "\n",
    "* In cross validation we consider all available training test splits, and look at the mean score across all of these *folds*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cross_validation.svg\" width=100%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "cross_val_score(model, X, y, cv=5, scoring='r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How we design the folds matters: we want each subset of the data to be a fair sample of the whole.\n",
    "\n",
    "* In this problem, we want to select the LSTAT values randomly (rather than sequentially)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "shuffle_split = ShuffleSplit(len(X), 20, test_size=0.4)\n",
    "cross_val_score(model, X, y, cv=shuffle_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE = cross_val_score(model, X, y, cv=shuffle_split, scoring='mean_squared_error')\n",
    "GE,errGE = np.mean(MSE),np.std(MSE)\n",
    "print \"Generalization error:\",GE,\"+/-\",errGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R2 = cross_val_score(model, X, y, cv=shuffle_split, scoring='r2')\n",
    "meanR2,errR2 = np.mean(R2),np.std(R2)\n",
    "print \"Mean score:\",meanR2,\"+/-\",errR2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Expansion\n",
    "\n",
    "* Let's expand our linear model to include some higher order terms (quadratic, cubic etc). This can be done by adding additional feature columns to the design matrix $X$. We are still just predicting $y$, but now we'll be asking for more coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "XX = poly.fit_transform(X)\n",
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polymodel = linear_model.LinearRegression()\n",
    "\n",
    "poly_split = ShuffleSplit(len(XX), 20, test_size=0.4)\n",
    "\n",
    "R2 = cross_val_score(polymodel, XX, y, cv=poly_split, scoring='r2')\n",
    "\n",
    "meanR2,errR2 = np.mean(R2),np.std(R2)\n",
    "print \"Mean score:\",meanR2,\"+/-\",errR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions with models:\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "y_straightline = cross_val_predict(model, X, y, cv=10)\n",
    "y_polynomial = cross_val_predict(polymodel, XX, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot outputs:\n",
    "plt.scatter(X, y,  color='black', alpha=0.1)\n",
    "plt.plot(X, y_straightline, color='blue', linewidth=2, alpha=0.4)\n",
    "plt.plot(X, y_polynomial, color='green', linewidth=2, alpha=0.4)\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this example, the polynomial degree is a control parameter that needs to be set: we can search this parameter space for the value that gives the highest average cross validation score (or lowest generalization error). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "* The Boston dataset has 13 attributes, more than one of which might contain information about house prices in the city. Let's train a linear model on all these attributes, and see if we can improve our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a linear model:\n",
    "supermodel = linear_model.LinearRegression()\n",
    "\n",
    "# Use all the data, and set up a 20-fold cross validation run:\n",
    "super_split = ShuffleSplit(len(boston.data), 20, test_size=0.4)\n",
    "\n",
    "# Carry out the cross-validation of the model, training, testing and reporting:\n",
    "R2 = cross_val_score(supermodel, boston.data, boston.target, cv=super_split, scoring='r2')\n",
    "\n",
    "# Compute our model prediction accuracy score, for comparison with other models:\n",
    "meanR2,errR2 = np.mean(R2),np.std(R2)\n",
    "print \"Mean score:\",meanR2,\"+/-\",errR2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We just went from a simple hypothesis (house price depends on LSTAT) to a very much more complex one (house price could depend on all of our 13 measured attributes) in one step. The data analysis is *automated*, in the sense that we simply fed our machine new inputs and it processed them.\n",
    "\n",
    "\n",
    "* Using all our data, we are now better at predicting house prices - *but we have gained no new understanding of how the Boston housing market works.*\n",
    "\n",
    "\n",
    "* Machine learning algorithms are designed to make good use of big, complex datasets, where there are likely to be many more correlations and connections than we have thought of yet. In this *data-driven* approach we assume that we will be able to make better predictions by using flexible, \"non-parametric\" methods that scale with the size of the dataset and allow new relationships to emerge empirically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Let's see a couple of machine learning applications in astronomy.](../examples/SDSSCatalog/Quasars.ipynb) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
