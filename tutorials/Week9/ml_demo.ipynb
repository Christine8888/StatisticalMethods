{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reminder!\n",
    "\n",
    "After pulling down the tutorial notebook, immediately make a copy. Then do not modify the original. Do your work in the copy. This will prevent the possibility of git conflicts should the version-controlled file change at any point in the future. (The same exhortation applies to homeworks.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 9 Tutorial \n",
    "\n",
    "## Introduction to Machine Learning\n",
    "\n",
    "In this notebook you will start to explore the `scikit-learn` ML python package, and see how it supports a range of machine learning models with a uniform terminology and API, and emphasize model evaluation by cross-validation. \n",
    "\n",
    "> Credit: some of the material in this tutorial is based on Andy Mueller's `scikit-learn` tutorial from the 2015 edition of \"Astro Hack Week\". The SDSS examples are based on a tutorial by Josh Bloom. \n",
    "\n",
    "### Requirements\n",
    "\n",
    "You will need to `pip install scikit-learn` and check that you have v0.18 or higher as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Simple Example: The Digits Dataset\n",
    "\n",
    "* Let's take a look at one of the `SciKit-Learn` example datasets, `digits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(digits.images[23], cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target[23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "* In `SciKit-Learn`,  `data` contains the design matrix $X$, and is a `numpy` array of shape $(N, P)$\n",
    "\n",
    "\n",
    "* `target` contains the response variables $y$, and is a `numpy` array of shape $(N)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(digits.data, digits.target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other Example Datasets\n",
    "\n",
    "`SciKit-Learn` provides 5 \"toy\" datasets for tutorial purposes, all `load`-able in the same way:\n",
    "\n",
    "Name        | Description\n",
    "------------|:---------------------------------------\n",
    "`boston`\t| Boston house-prices, with 13 associated measurements (R)\n",
    "`iris`\t    | Fisher's iris classifications (based on 4 characteristics) (C)\n",
    "`diabetes`\t| Diabetes (x vs y) (R)\n",
    "`digits`\t| Hand-written digits, 8x8 images with classifications (C)\n",
    "`linnerud`\t| Linnerud: 3 exercise and 3 physiological data (R)\n",
    "\n",
    "\n",
    "* \"R\" and \"C\" indicate that the problem to be solved is either a regression or a classification, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Looking for Structure\n",
    "\n",
    "* A model's ability to make predictions depends on there being _structure_ in the data\n",
    "\n",
    "* If structure is present the data are informative, and vice versa.\n",
    "\n",
    "* Feature design takes thought; thinking is aided by _data visualization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing the Boston house price data:\n",
    "\n",
    "import corner\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "plot = np.concatenate((X, np.atleast_2d(y).T), axis=1)\n",
    "labels = np.append(boston.feature_names,'MEDV')\n",
    "\n",
    "corner.corner(plot, labels=labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Fitting a Straight Line with `SciKit-Learn`\n",
    "\n",
    "For a first application, let's see the straight line fitting problem solved via the machine learning approach. In the process, we'll look at how model (prediction) accuracy is quantified, and then generalized via cross-validation.  \n",
    "\n",
    "### Further Reading\n",
    "\n",
    "Ivezic Sections 8.1 and 8.2 (linear regression), and Section 8.11 for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Regression\n",
    "\n",
    "Straight line fitting is a [linear regression](http://scikit-learn.org/stable/modules/linear_model.html) problem - and an example of predictive learning. \n",
    "\n",
    "A predictive model can be said to have been \"fitted\" to the data when an assumed _loss function_ has been minimized. A popular choice of minimized loss function is the following, corresponding to the method of \"ordinary least squares\":\n",
    "\n",
    "$$ \\text{min}_{w, b} \\sum_i || w^\\mathsf{T}x_i + b  - y_i||^2 $$\n",
    "\n",
    "> While this loss function is derivable from statistical principles, the machine only needs it to be encoded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "If we fit a straight line to a subset of the data (the training set), the accuracy of the linear model's predictions in the remainder of the data (the test set) can be checked. \n",
    "\n",
    "Let's fit some test data with a straight line using the `SciKit-Learn` library, and see how accurately we can make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Load the boston dataset, and focus on just one attribute: \n",
    "# LSTAT (attribute 12)\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# Package into design matrix X and target vector y:\n",
    "X = np.atleast_2d(boston.data[:,12]).T\n",
    "y = np.atleast_2d(boston.target).T\n",
    "\n",
    "# Make a training/test split:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color='black')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `Linear` Model\n",
    "\n",
    "`scikit-learn` machine learning models have a common API:\n",
    "\n",
    "* a `fit` method that optimizes the model's internal parameters given training data features and target values\n",
    "\n",
    "* a `predict` method that returns model-predicted target values given test data features\n",
    "\n",
    "* various `score`s for quantifying performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create linear regression model object:\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training set:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# The coefficients:\n",
    "print(\"Coefficients:\", model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scoring\n",
    "\n",
    "* The \"mean squared error\" between the model predictions and the truth is a useful metric: minimizing MSE corresponds to minimizing the \"empirical risk,\" defined as the mean value loss function averaged over the available data samples, where the loss function is quadratic:\n",
    "\n",
    "\n",
    "$\\;\\;\\;\\;\\;{\\rm MSE} = \\mathcal{E} \\left[ (\\hat{y} - y^{\\rm true})^2 \\right] = \\mathcal{E} \\left[ (\\hat{y} - \\bar{y} + \\bar{y} - y^{\\rm true})^2 \\right] = \\mathcal{E} \\left[ (\\hat{y} - \\bar{y})^2 \\right] + (\\bar{y} - y^{\\rm true})^2$\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; = {\\rm var}(\\hat{y}) + {\\rm bias}^2(\\hat{y})$\n",
    "\n",
    "\n",
    "* In general, different models reach different balances between the variance and bias of their predictions\n",
    "\n",
    "* A particular choice of loss function leads to a corresponding minimized risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The mean square prediction error:\n",
    "print(\"Training data: MSE = %.2f\"\n",
    "      % np.mean((model.predict(X_train) - y_train) ** 2))\n",
    "print(\"Test data: MSE = %.2f\"\n",
    "      % np.mean((model.predict(X_test) - y_test) ** 2))\n",
    "\n",
    "# The \"explained variance\" R2 score: 1 is perfect prediction:\n",
    "print('Training data: R^2 score = %.2f' % model.score(X_train, y_train))\n",
    "print('Test data: R^2 score = %.2f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### R2 scores\n",
    "\n",
    "* The \"explained variance\" $R^2$ \"score\" is defined as $(1 - u/v)$, where $u$ is the *regression sum of squares* $\\sum (y_{\\rm true} - y_{\\rm pred})^2$ and $v$ is the *residual sum of squares* $\\sum (y_{\\rm true} - \\overline{y_{\\rm true}})^2)$. \n",
    "\n",
    "\n",
    "* The best possible $R^2$ score is 1.0. A model that has mean squared error equal to the variance in the data gets a score of zero. Models that do systematically worse than this have negative $R^2$ scores.\n",
    "\n",
    "\n",
    "* In general we expect the training score to be higher than the test score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot outputs:\n",
    "plt.scatter(X_test, y_test,  color='black')\n",
    "plt.plot(X_test, model.predict(X_test), color='blue', linewidth=3)\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Questions:\n",
    "\n",
    "* How is this procedure different from previous occasions we have fitted a straight line? \n",
    "\n",
    "* Is it \"Frequentist\" or \"Bayesian\"? Why? \n",
    "\n",
    "* Does it follow the likelihood principle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimizing Model Prediction Accuracy\n",
    "\n",
    "* In supervised machine learning the usual goal is to make the most accurate predictions we can - which means neither over-fitting nor under-fitting the data \n",
    "\n",
    "* Above, we made one training/test split, and computed the (mean squared) prediction error. The model that minimizes the *generalized prediction error* can be found (approximately) with *cross validation*.\n",
    "\n",
    "* In cross validation we consider multiple training/test splits, and look at the _mean score_ across all of these _\"folds.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "cross_val_score(model, X, y, cv=5, scoring='r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross Validation Fold Design\n",
    "\n",
    "* How we design the folds matters: we want each subset of the data to be a _fair sample_ of the whole.\n",
    "\n",
    "\n",
    "* In this problem, we want to select the LSTAT values randomly (rather than sequentially), and so we make a `ShuffleSplit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "shuffle_split = ShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "cross_val_score(model, X, y, cv=shuffle_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generalized Scoring\n",
    "\n",
    "With our 10 fold shuffle splits, we can calculate generalized accuracy scores  - that could be used in a cross-validation model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = cross_val_score(model, X, y, cv=shuffle_split, scoring='neg_mean_squared_error')\n",
    "GE, errGE = -np.mean(MSE), np.std(MSE)/np.sqrt(len(MSE))\n",
    "print(\"Generalization error:\", GE, \"+/-\", errGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = cross_val_score(model, X, y, cv=shuffle_split, scoring='r2')\n",
    "meanR2, errR2 = np.mean(R2), np.std(R2)/np.sqrt(len(R2))\n",
    "print(\"Generalized R2 score:\", meanR2, \"+/-\", errR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Expansion\n",
    "\n",
    "* Let's expand our linear model to include some higher order terms (quadratic, cubic etc). This can be done by adding additional feature columns to the design matrix $X$. We are still just predicting $y$, but now we'll be asking for more coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "XX = poly.fit_transform(X)\n",
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel = linear_model.LinearRegression()\n",
    "\n",
    "poly_split = ShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "R2 = cross_val_score(polymodel, XX, y, cv=poly_split, scoring='r2')\n",
    "\n",
    "poly_meanR2, poly_errR2 = np.mean(R2), np.std(R2)/np.sqrt(len(R2))\n",
    "print(\"Polynomial: generalized R^2 score:\", np.round(poly_meanR2, 2), \"+/-\", np.round(poly_errR2, 2))\n",
    "print(\"Straight line: generalized R^2 score:\", np.round(meanR2, 2), \"+/-\", np.round(errR2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Checking\n",
    "\n",
    "As usual, it's a good idea to check the model's performance by visualizing its predictions in data space\n",
    "\n",
    "\n",
    "We can make one model prediction for each training set in a set of folds, and plot all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validation:\n",
    "\n",
    "y_straightline = cross_val_predict(model, X, y, cv=10)\n",
    "y_polynomial = cross_val_predict(polymodel, XX, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot outputs:\n",
    "plt.scatter(X, y,  color='black', alpha=0.1)\n",
    "plt.plot(X, y_straightline, color='blue', linewidth=2, alpha=0.4)\n",
    "plt.plot(X, y_polynomial, color='green', linewidth=2, alpha=0.4)\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In this example, the polynomial degree is a control parameter that needs to be set: we can search this parameter space for the value that gives the highest average cross validation score (or lowest generalization error). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "* The Boston dataset has 13 attributes, more than one of which might contain information about house prices in the city. Let's train a linear model on all these attributes, and see if we can improve our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear model:\n",
    "supermodel = linear_model.LinearRegression()\n",
    "\n",
    "# Use all the data, and set up a 10-fold cross validation run:\n",
    "super_split = ShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "# Carry out the cross-validation of the model, training, testing and reporting:\n",
    "R2 = cross_val_score(supermodel, boston.data, boston.target, cv=super_split, scoring='r2')\n",
    "                           \n",
    "# Compute our model prediction accuracy score, for comparison with other models:\n",
    "hpmeanR2, hperrR2 = np.mean(R2), np.std(R2)/np.sqrt(len(R2))\n",
    "print(\"Hyperplane: generalized R^2 score:\", np.round(hpmeanR2, 2), \"+/-\", np.round(hperrR2, 2))\n",
    "print(\"Straight line: generalized R^2 score:\", np.round(meanR2, 2), \"+/-\", np.round(errR2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What just happened?\n",
    "\n",
    "* We just went from a simple hypothesis (median house price `MEDV` depends on `LSTAT`) to a very much more complex one (house price could depend on all of our 13 measured attributes) in one step. The data analysis is *automated*, in the sense that we simply fed our machine new inputs and it processed them.\n",
    "\n",
    "\n",
    "* Using all our data, we are now better at predicting house prices - *but we have gained no new understanding of how the Boston housing market works.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
