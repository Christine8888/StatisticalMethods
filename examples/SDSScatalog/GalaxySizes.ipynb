{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrating Observed and Intrinsic Object Properties:\n",
    "# SDSS \"Galaxy\" Sizes\n",
    "\n",
    "\n",
    "* In a catalog, each galaxy's measurements come with \"error bars\" providing information about how *uncertain* we should be about each property of each galaxy.\n",
    "\n",
    "* This means that the distribution of \"observed\" galaxy properties (as reported in the catalog) is not the same as the underlying or \"intrinsic\" distribution.\n",
    "\n",
    "* Let's look at the distribution of *observed sizes* in the SDSS photometric object catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SDSS\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "galaxies = \"SELECT top 1000 \\\n",
    "petroR50_i AS size, \\\n",
    "petroR50Err_i AS err \\\n",
    "FROM PhotoObjAll \\\n",
    "WHERE \\\n",
    "(type = '3' AND petroR50Err_i > 0)\"\n",
    "print galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download data. This can take a few moments...\n",
    "data = SDSS.select(galaxies)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p downloads\n",
    "data.to_csv(\"downloads/SDSSgalaxysizes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Distribution of Observed SDSS \"Galaxy\" Sizes\n",
    "\n",
    "Let's look at a histogram of galaxy sizes, for 1000 objects classified as \"galaxies\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"downloads/SDSSgalaxysizes.csv\",usecols=[\"size\",\"err\"])\n",
    "\n",
    "data['size'].hist(bins=np.linspace(0.0,5.0,100),figsize=(12,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to notice:\n",
    "\n",
    "* No small objects (why not?)\n",
    "* A \"tail\" to large size\n",
    "* Some very large sizes that look a little odd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Are these large galaxies *actually* large, or have they just been measured that way?\n",
    "Let's look at the reported uncertainties on these sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.plot(kind='scatter', x='size', y='err',s=100,figsize=(12,7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Mock Data\n",
    "\n",
    "* Let's look at how distributions like this one can come about, by making a **generative model** for this dataset.\n",
    "\n",
    "\n",
    "* First, let's imagine a set of perfectly measured galaxies. They won't all have the same size, because the Universe isn't like that. Let's suppose the logarithm of their *intrinsic sizes* are drawn from a Gaussian distribution of width $S$ and mean $\\mu$. \n",
    "\n",
    "\n",
    "* To model one mock galaxy, we *draw a sample from this distribution*. To model the whole dataset, we draw 1000 samples.\n",
    "\n",
    "\n",
    "* Note that this is a similar activity to making random catalogs for use in correlation function summaries; here, though, we want to start comparing real data with mock data to begin *understanding* it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_galaxies(mu=np.log10(1.5),S=0.3,N=1000):\n",
    "    return pd.DataFrame({'size' : 10.0**(mu + S*np.random.randn(N))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mu = np.log10(1.5)\n",
    "S = 0.05\n",
    "intrinsic = generate_galaxies(mu=mu,S=S,N=1000)\n",
    "\n",
    "intrinsic.hist(bins=np.linspace(0.0,5.0,100),figsize=(12,7),color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some observational uncertainty. We can model this by drawing random Gaussian offsets $\\epsilon$ and add one to each intrinsic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_noise(sigma=0.3,N=1000):\n",
    "    return pd.DataFrame({'size' : sigma*np.random.randn(N)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma = 0.3\n",
    "errors = make_noise(sigma=sigma,N=1000)\n",
    "\n",
    "observed = intrinsic + errors\n",
    "\n",
    "observed.hist(bins=np.linspace(0.0,5.0,100),figsize=(12,7),color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "both = pd.DataFrame({'SDSS': data['size'], 'Model': observed['size']}, columns=['SDSS', 'Model'])\n",
    "both.hist(alpha=0.5,bins=np.linspace(0.0,5.0,100),figsize=(12,7))\n",
    "\n",
    "# data['size'].hist(bins=np.linspace(0.0,5.0,100),figsize=(12,7))\n",
    "# observed.hist(bins=np.linspace(0.0,5.0,100),figsize=(12,7),color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How did we do? Is this a good model for our data?\n",
    "\n",
    "Play around with the _parameters_ $\\mu$, $S$ and $\\sigma$ and see if you can get a better match to the observed distribution of sizes.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing: let's look at the variances of these distributions.\n",
    "\n",
    "Recall: \n",
    "\n",
    "$V(x) = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\nu)^2$\n",
    "\n",
    "If $\\nu$, the population mean of $x$, is not known, an _estimator_ for $V$ is \n",
    "\n",
    "$\\hat{V}(x) = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2$\n",
    "\n",
    "where $\\bar{x} = \\frac{1}{N} \\sum_{i=1}^N x_i$, the _sample mean_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V_data = np.var(data['size'])\n",
    "\n",
    "print \"Variance of the SDSS distribution = \",V_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V_int   = np.var(intrinsic['size'])\n",
    "V_noise = np.var(errors['size'])\n",
    "V_obs = np.var(observed['size'])\n",
    "\n",
    "print \"Variance of the intrinsic distribution = \", V_int\n",
    "print \"Variance of the noise = \", V_noise\n",
    "print \"Variance of the observed distribution = \",  V_int + V_noise, \\\n",
    "  \"cf\", V_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may recall this last result from previous statistics courses.\n",
    "\n",
    "**Why is the variance of our mock dataset's galaxy sizes so much smaller than that of the SDSS sample?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Distributions\n",
    "\n",
    "In the above example we drew *samples* from two *probability distributions*:\n",
    "\n",
    "* The intrinsic size distribution, ${\\rm Pr}(R_{\\rm true}|\\mu,S)$\n",
    "\n",
    "\n",
    "* The \"error\" distribution, ${\\rm Pr}(R_{\\rm obs}|R_{\\rm true},\\sigma)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The procedure of drawing numbers from the first, and then adding numbers from the second, produced *mock data* - which then appeared to have been drawn from:\n",
    "\n",
    "* ${\\rm Pr}(R_{\\rm obs}|\\mu,S)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Q: What would we do differently if we wanted to simulate 1 Galaxy?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The three distributions are related by an integral:\n",
    "\n",
    "${\\rm Pr}(R_{\\rm obs}|\\mu,S) = \\int {\\rm Pr}(R_{\\rm obs}|R_{\\rm true},\\sigma) \\; {\\rm Pr}(R_{\\rm true}|\\mu,S) \\; dR_{\\rm true}$\n",
    "\n",
    "When we only plot the 1D histogram of *observed* sizes, we are *summing over* or \"marginalizing out\" the intrinsic ones. \n",
    "\n",
    "Often it is useful to visualize all 1 and 2D projections of a multivariate probability distribution - like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade triangle_plot\n",
    "import triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_plot = np.array([observed['size'],intrinsic['size']]).transpose()\n",
    "fig = triangle.corner(to_plot,labels=['Observed size','Intrinsic size'],range=[(0.0,3.0),(0.0,3.0)],color='Blue',plot_datapoints=False, fill_contours=True,\n",
    "                levels=[0.68, 0.95], bins=50, smooth=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Graphical Models\n",
    "\n",
    "We can draw a diagram representing the above combination of probability distributions, that:\n",
    "\n",
    "* Shows the dependencies between variables\n",
    "* Gives you a recipe for generating *mock data*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[We can also do this in python, using the `daft` package.](FirstPGM.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"samplingdistributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Where should $\\sigma$ go?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
